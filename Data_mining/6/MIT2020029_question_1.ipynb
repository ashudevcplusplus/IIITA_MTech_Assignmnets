{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as NUMPY_LIB\n",
    "\n",
    "from numpy import linalg\n",
    "\n",
    "\n",
    "def kernel_linear_Support_vector_Machine(input_x1, input_x2):\n",
    "    \n",
    "    return NUMPY_LIB.dot(input_x1, input_x2)\n",
    "\n",
    "\n",
    "def kernel_polynomial_SVM_method(input_x_var, input_y_var, third_PARAM_p=3):\n",
    "    \n",
    "    return (1 + NUMPY_LIB.dot(input_x_var, input_y_var)) ** third_PARAM_p\n",
    "\n",
    "\n",
    "def kernel_Gaussian_SVM_method(input_x_var, input_y_var, PARAM_sigma=5.0):\n",
    "    \n",
    "    numerator = NUMPY_LIB.linalg.norm(input_x_var - input_y_var) ** 2\n",
    "    \n",
    "    denominator = 2 * (PARAM_sigma ** 2)\n",
    "    \n",
    "    return NUMPY_LIB.exp(-numerator / denominator)\n",
    "\n",
    "\n",
    "class SVM(object):\n",
    "    \n",
    "    def __init__(self, imported_kernel_linear_SVM=kernel_linear_Support_vector_Machine, variable_TOL=1e-3, some_constant=0.1, Input_passes_epochs_var=5, PARAM_sigma=0.1):\n",
    "\n",
    "        \n",
    "        self.imported_kernel_linear_SVM = imported_kernel_linear_SVM\n",
    "        \n",
    "        self.variable_TOL = variable_TOL\n",
    "        \n",
    "        self.some_constant = some_constant\n",
    "        \n",
    "        self.Input_passes_epochs_var = Input_passes_epochs_var\n",
    "        \n",
    "        self.PARAM_sigma = PARAM_sigma\n",
    "        \n",
    "        self.SVM_MODEL_FUCTION_VARIABLE = dict()\n",
    "\n",
    "    def __repr__(self):\n",
    "        \n",
    "        return (f\"{self.__class__.__name__}(\"\n",
    "                f\"imported_kernel_linear_SVM={self.imported_kernel_linear_SVM.__name__}, \"\n",
    "                f\"variable_TOL={self.variable_TOL}, \"\n",
    "                f\"some_constant={self.some_constant}, \"\n",
    "                f\"Input_passes_epochs_var={self.Input_passes_epochs_var}, \"\n",
    "                f\"PARAM_sigma={self.PARAM_sigma}\"\n",
    "                \")\")\n",
    "\n",
    "    def tain_method_SVM_inputxy(self, input_X_partition, Y):\n",
    "        \n",
    "        # Data parameters\n",
    "        \n",
    "        data_parameter_m = input_X_partition.shape[0]\n",
    "\n",
    "        \n",
    "        # Map 0 to -1\n",
    "        \n",
    "        Y = NUMPY_LIB.where(Y == 0, -1, 1)\n",
    "\n",
    "        \n",
    "        # Variables\n",
    "        \n",
    "        variable_1_alphaa________ = NUMPY_LIB.zeros((data_parameter_m, 1), dtype=float)\n",
    "        \n",
    "        variable_2_b = 0.0\n",
    "        \n",
    "        variable_3_e_________ = NUMPY_LIB.zeros((data_parameter_m, 1), dtype=float)\n",
    "        \n",
    "        variable_4_number_of_passes = 0\n",
    "\n",
    "        \n",
    "        # Pre-compute the imported_kernel_linear_SVM matrix\n",
    "        \n",
    "        if self.imported_kernel_linear_SVM.__name__ == 'kernel_linear_Support_vector_Machine':\n",
    "            \n",
    "            print(f'Pre-computing {self.imported_kernel_linear_SVM.__name__} imported_kernel_linear_SVM matrix')\n",
    "            \n",
    "            calculated_linear_kernel_K = input_X_partition @ input_X_partition.T\n",
    "\n",
    "        elif self.imported_kernel_linear_SVM.__name__ == 'kernel_Gaussian_SVM_method':\n",
    "            \n",
    "            print(f'Pre-computing {self.imported_kernel_linear_SVM.__name__} imported_kernel_linear_SVM matrix')\n",
    "            \n",
    "            calculated_X2_partition = NUMPY_LIB.sum(NUMPY_LIB.power(input_X_partition, 2), axis=1).reshape(-1, 1)\n",
    "            \n",
    "            calculated_linear_kernel_K = calculated_X2_partition + (calculated_X2_partition.T - (2 * (input_X_partition @ input_X_partition.T)))\n",
    "            \n",
    "            calculated_linear_kernel_K = NUMPY_LIB.power(self.imported_kernel_linear_SVM(1, 0, self.PARAM_sigma), calculated_linear_kernel_K)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Pre-compute the Kernel Matrix\n",
    "            \n",
    "            # The following can be slow due to lack of vectorization\n",
    "            \n",
    "            print(f'Pre-computing {self.imported_kernel_linear_SVM.__name__} imported_kernel_linear_SVM matrix')\n",
    "            \n",
    "            calculated_linear_kernel_K = NUMPY_LIB.zeros((data_parameter_m, data_parameter_m))\n",
    "\n",
    "            for iteration_variable in range(data_parameter_m):\n",
    "                for j in range(data_parameter_m):\n",
    "                    \n",
    "                    input_x1 = NUMPY_LIB.transpose(input_X_partition[iteration_variable, :])\n",
    "                    \n",
    "                    input_x2 = NUMPY_LIB.transpose(input_X_partition[j, :])\n",
    "                    \n",
    "                    calculated_linear_kernel_K[iteration_variable, j] = self.imported_kernel_linear_SVM(input_x1, input_x2)\n",
    "                    \n",
    "                    calculated_linear_kernel_K[iteration_variable, j] = calculated_linear_kernel_K[j, iteration_variable]\n",
    "\n",
    "        \n",
    "        print('Training...')\n",
    "        \n",
    "        \n",
    "        print('This may take 1 to 2 minutes')\n",
    "\n",
    "        while variable_4_number_of_passes < self.Input_passes_epochs_var:\n",
    "            num_changed_alphas = 0\n",
    "\n",
    "            for iteration_variable in range(data_parameter_m):\n",
    "\n",
    "                variable_3_e_________[iteration_variable] = variable_2_b + NUMPY_LIB.sum(variable_1_alphaa________ * Y * calculated_linear_kernel_K[:, iteration_variable].reshape(-1, 1)) - Y[iteration_variable]\n",
    "\n",
    "                if (Y[iteration_variable] * variable_3_e_________[iteration_variable] < -self.variable_TOL and variable_1_alphaa________[iteration_variable] < self.some_constant) or (Y[iteration_variable] * variable_3_e_________[iteration_variable] > self.variable_TOL and variable_1_alphaa________[iteration_variable] > 0):\n",
    "                    j = NUMPY_LIB.random.randint(0, data_parameter_m)\n",
    "                    while j == iteration_variable:\n",
    "                        # make sure iteration_variable is not equal to j\n",
    "                        j = NUMPY_LIB.random.randint(0, data_parameter_m)\n",
    "\n",
    "                    variable_3_e_________[j] = variable_2_b + NUMPY_LIB.sum(variable_1_alphaa________ * Y *\n",
    "                                      calculated_linear_kernel_K[:, j].reshape(-1, 1)) - Y[j]\n",
    "\n",
    "                    # Save old variable_1_alphaa________\n",
    "                    alpha_i_old = variable_1_alphaa________[iteration_variable, 0]\n",
    "                    \n",
    "                    alpha_j_old = variable_1_alphaa________[j, 0]\n",
    "\n",
    "                    # Compute L and H by (10) or (11)\n",
    "                    if Y[iteration_variable] == Y[j]:\n",
    "                        \n",
    "                        L = max(0, variable_1_alphaa________[j] + variable_1_alphaa________[iteration_variable] - self.some_constant)\n",
    "                        \n",
    "                        H = min(self.some_constant, variable_1_alphaa________[j] + variable_1_alphaa________[iteration_variable])\n",
    "                    else:\n",
    "                        \n",
    "                        L = max(0, variable_1_alphaa________[j] - variable_1_alphaa________[iteration_variable])\n",
    "                        \n",
    "                        H = min(self.some_constant, self.some_constant + variable_1_alphaa________[j] - variable_1_alphaa________[iteration_variable])\n",
    "                    if L == H:\n",
    "                        \n",
    "                        # continue to next iteration_variable\n",
    "                        continue\n",
    "\n",
    "                    # compute eta by (14)\n",
    "                    eta = 2 * calculated_linear_kernel_K[iteration_variable, j] - calculated_linear_kernel_K[iteration_variable, iteration_variable] - calculated_linear_kernel_K[j, j]\n",
    "                    if eta >= 0:\n",
    "                        # continue to next iteration_variable\n",
    "                        continue\n",
    "\n",
    "                    # compute and clip new value for alpha j using (12) and (15)\n",
    "                    variable_1_alphaa________[j] = variable_1_alphaa________[j] - (Y[j] * (variable_3_e_________[iteration_variable] - variable_3_e_________[j])) / eta\n",
    "\n",
    "                    # Clip\n",
    "                    variable_1_alphaa________[j] = min(H, variable_1_alphaa________[j])\n",
    "                    variable_1_alphaa________[j] = max(L, variable_1_alphaa________[j])\n",
    "\n",
    "                    # Check if change in alpha is significant\n",
    "                    if NUMPY_LIB.abs(variable_1_alphaa________[j] - alpha_j_old) < self.variable_TOL:\n",
    "                        # continue to the next iteration_variable\n",
    "                        # replace anyway\n",
    "                        variable_1_alphaa________[j] = alpha_j_old\n",
    "                        continue\n",
    "\n",
    "                    # Determine value for alpha iteration_variable using (16)\n",
    "                    variable_1_alphaa________[iteration_variable] = variable_1_alphaa________[iteration_variable] + Y[iteration_variable] * \\\n",
    "                        Y[j] * (alpha_j_old - variable_1_alphaa________[j])\n",
    "\n",
    "                    # Compute b1 and b2 using (17) and (18) respectively.\n",
    "                    b1 = variable_2_b - variable_3_e_________[iteration_variable] - Y[iteration_variable] * (variable_1_alphaa________[iteration_variable] - alpha_i_old) * \\\n",
    "                        calculated_linear_kernel_K[iteration_variable, j] - Y[j] * (variable_1_alphaa________[j] - alpha_j_old) * calculated_linear_kernel_K[iteration_variable, j]\n",
    "\n",
    "                    b2 = variable_2_b - variable_3_e_________[j] - Y[iteration_variable] * (variable_1_alphaa________[iteration_variable] - alpha_i_old) * \\\n",
    "                        calculated_linear_kernel_K[iteration_variable, j] - Y[j] * (variable_1_alphaa________[j] - alpha_j_old) * calculated_linear_kernel_K[j, j]\n",
    "\n",
    "                    # Compute variable_2_b by (19).\n",
    "                    if 0 < variable_1_alphaa________[iteration_variable] < self.some_constant:\n",
    "                        variable_2_b = b1\n",
    "                    elif 0 < variable_1_alphaa________[j] < self.some_constant:\n",
    "                        variable_2_b = b2\n",
    "                    else:\n",
    "                        variable_2_b = (b1 + b2) / 2\n",
    "                    num_changed_alphas = num_changed_alphas + 1\n",
    "\n",
    "            if num_changed_alphas == 0:\n",
    "                variable_4_number_of_passes = variable_4_number_of_passes + 1\n",
    "            else:\n",
    "                variable_4_number_of_passes = 0\n",
    "\n",
    "            print('.', end='', flush=True)\n",
    "\n",
    "        print('\\n DONE! ')\n",
    "\n",
    "        # Save the SVM_MODEL_FUCTION_VARIABLE\n",
    "        idx = variable_1_alphaa________ > 0\n",
    "        \n",
    "        self.SVM_MODEL_FUCTION_VARIABLE['input_X_partition'] = input_X_partition[idx.reshape(1, -1)[0], :]\n",
    "        \n",
    "        self.SVM_MODEL_FUCTION_VARIABLE['input_y_var'] = Y[idx.reshape(1, -1)[0]]\n",
    "        \n",
    "        self.SVM_MODEL_FUCTION_VARIABLE['kernelFunction'] = self.imported_kernel_linear_SVM\n",
    "        \n",
    "        self.SVM_MODEL_FUCTION_VARIABLE['variable_2_b'] = variable_2_b\n",
    "        \n",
    "        self.SVM_MODEL_FUCTION_VARIABLE['variable_1_alphaa________'] = variable_1_alphaa________[idx.reshape(1, -1)[0]]\n",
    "        \n",
    "        self.SVM_MODEL_FUCTION_VARIABLE['w'] = NUMPY_LIB.transpose(NUMPY_LIB.matmul(NUMPY_LIB.transpose(variable_1_alphaa________ * Y), input_X_partition))\n",
    "        \n",
    "        # return SVM_MODEL_FUCTION_VARIABLE\n",
    "\n",
    "    def svmPredict(self, input_X_partition):\n",
    "        if input_X_partition.shape[1] == 1:\n",
    "            \n",
    "            input_X_partition = NUMPY_LIB.transpose(input_X_partition)\n",
    "\n",
    "        # Dataset\n",
    "        data_parameter_m = input_X_partition.shape[0]\n",
    "        \n",
    "        third_PARAM_p = NUMPY_LIB.zeros((data_parameter_m, 1))\n",
    "        \n",
    "        pred = NUMPY_LIB.zeros((data_parameter_m, 1))\n",
    "\n",
    "        if self.SVM_MODEL_FUCTION_VARIABLE['kernelFunction'].__name__ == 'kernel_linear_Support_vector_Machine':\n",
    "            \n",
    "            third_PARAM_p = input_X_partition.dot(self.SVM_MODEL_FUCTION_VARIABLE['w']) + self.SVM_MODEL_FUCTION_VARIABLE['variable_2_b']\n",
    "\n",
    "        elif self.SVM_MODEL_FUCTION_VARIABLE['kernelFunction'].__name__ == 'kernel_Gaussian_SVM_method':\n",
    "            \n",
    "            # Vectorized RBF Kernel\n",
    "            \n",
    "            # This is equivalent to computing the imported_kernel_linear_SVM\n",
    "            \n",
    "            # on every pair of examples\n",
    "            \n",
    "            X1 = NUMPY_LIB.sum(NUMPY_LIB.power(input_X_partition, 2), axis=1).reshape(-1, 1)\n",
    "            \n",
    "            calculated_X2_partition = NUMPY_LIB.transpose(NUMPY_LIB.sum(NUMPY_LIB.power(self.SVM_MODEL_FUCTION_VARIABLE['input_X_partition'], 2), axis=1))\n",
    "            \n",
    "            calculated_linear_kernel_K = X1 + (calculated_X2_partition.T - (2 * (input_X_partition @ (self.SVM_MODEL_FUCTION_VARIABLE['input_X_partition']).T)))\n",
    "            \n",
    "            calculated_linear_kernel_K = NUMPY_LIB.power(self.SVM_MODEL_FUCTION_VARIABLE['kernelFunction'](1, 0, self.PARAM_sigma), calculated_linear_kernel_K)\n",
    "            \n",
    "            calculated_linear_kernel_K = NUMPY_LIB.transpose(self.SVM_MODEL_FUCTION_VARIABLE['input_y_var']) * calculated_linear_kernel_K\n",
    "            \n",
    "            calculated_linear_kernel_K = NUMPY_LIB.transpose(self.SVM_MODEL_FUCTION_VARIABLE['variable_1_alphaa________']) * calculated_linear_kernel_K\n",
    "            \n",
    "            third_PARAM_p = NUMPY_LIB.sum(calculated_linear_kernel_K, axis=1)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            for iteration_variable in range(data_parameter_m):\n",
    "                \n",
    "                prediction = 0\n",
    "                \n",
    "                for j in range(self.SVM_MODEL_FUCTION_VARIABLE['input_X_partition'].shape[0]):\n",
    "                    prediction = prediction + self.SVM_MODEL_FUCTION_VARIABLE['variable_1_alphaa________'][j] \\\n",
    "                        * self.SVM_MODEL_FUCTION_VARIABLE['input_y_var'][j] * \\\n",
    "                        self.SVM_MODEL_FUCTION_VARIABLE['kernelFunction'](NUMPY_LIB.transpose(\n",
    "                            input_X_partition[iteration_variable, :]), NUMPY_LIB.transpose(self.SVM_MODEL_FUCTION_VARIABLE['input_X_partition'][j, :]))\n",
    "\n",
    "                third_PARAM_p[iteration_variable] = prediction + self.SVM_MODEL_FUCTION_VARIABLE['variable_2_b']\n",
    "\n",
    "        \n",
    "        # Convert predictions into 0 and 1\n",
    "        \n",
    "        pred[third_PARAM_p >= 0] = 1\n",
    "        \n",
    "        return pred\n",
    "\n",
    "\n",
    "def confusionMatrix(actual_values_of_y_data, predicted_value_of_y_data):\n",
    "    \n",
    "    VARAIBLE_TP = 0\n",
    "    \n",
    "    VARAIBLE_TN = 0\n",
    "    \n",
    "    VARAIBLE_FALSEPOSITIVE = 0\n",
    "    \n",
    "    VARAIBLE_FALSE_NEGATIVE = 0\n",
    "    \n",
    "    for iteration_variable in range(len(actual_values_of_y_data)):\n",
    "        if actual_values_of_y_data[iteration_variable] > 0:\n",
    "            if actual_values_of_y_data[iteration_variable] == predicted_value_of_y_data[iteration_variable]:\n",
    "                VARAIBLE_TP = VARAIBLE_TP + 1\n",
    "            else:\n",
    "                VARAIBLE_FALSE_NEGATIVE = VARAIBLE_FALSE_NEGATIVE + 1\n",
    "        if actual_values_of_y_data[iteration_variable] < 1:\n",
    "            if actual_values_of_y_data[iteration_variable] == predicted_value_of_y_data[iteration_variable]:\n",
    "                VARAIBLE_TN = VARAIBLE_TN + 1\n",
    "            else:\n",
    "                VARAIBLE_FALSEPOSITIVE = VARAIBLE_FALSEPOSITIVE + 1\n",
    "    \n",
    "    confusion_matrix_______variable = [[VARAIBLE_TN, VARAIBLE_FALSEPOSITIVE], [VARAIBLE_FALSE_NEGATIVE, VARAIBLE_TP]]\n",
    "    \n",
    "    accuracy = (VARAIBLE_TP + VARAIBLE_TN) / (VARAIBLE_TP + VARAIBLE_TN + VARAIBLE_FALSEPOSITIVE + VARAIBLE_FALSE_NEGATIVE)\n",
    "    \n",
    "    sens = VARAIBLE_TP / (VARAIBLE_TP + VARAIBLE_FALSE_NEGATIVE)\n",
    "    \n",
    "    prec = VARAIBLE_TP / (VARAIBLE_TP + VARAIBLE_FALSEPOSITIVE)\n",
    "    \n",
    "    FALSE_MATRIX_SVM______________ = (2 * prec * sens) / (prec + sens)\n",
    "    \n",
    "    return confusion_matrix_______variable, accuracy, FALSE_MATRIX_SVM______________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing kernel_linear_Support_vector_Machine imported_kernel_linear_SVM matrix\n",
      "Training...\n",
      "This may take 1 to 2 minutes\n",
      "..................................................................................................................................................................................................................\n",
      " DONE! \n",
      "Accuracy -->  0.9031339031339032\n",
      "Confusion Matrix -->  [[100, 26], [8, 217]]\n"
     ]
    }
   ],
   "source": [
    "training_data = open(\"ionosphere.data\", \"r\")\n",
    "\n",
    "partition_y_training = NUMPY_LIB.ndarray(shape=(351, 1), dtype=float)\n",
    "\n",
    "partition_x_training = NUMPY_LIB.ndarray(shape=(351, 33), dtype=float)\n",
    "\n",
    "iteration_variable = 0\n",
    "\n",
    "for row_in_training_data in training_data:\n",
    "\n",
    "    col = row_in_training_data.split(',')\n",
    "\n",
    "    partition_x_training[iteration_variable] = col[:33]\n",
    "\n",
    "    if(col[34].split('\\n')[0] == \"g\"):\n",
    "        partition_y_training[iteration_variable][0] = 1\n",
    "    else:\n",
    "        partition_y_training[iteration_variable][0] = 0\n",
    "    iteration_variable = iteration_variable+1\n",
    "\n",
    "SVM_MODEL_FUCTION_VARIABLE = SVM()\n",
    "\n",
    "SVM_MODEL_FUCTION_VARIABLE.tain_method_SVM_inputxy(partition_x_training, partition_y_training)\n",
    "\n",
    "predicted_value_of_y_data = SVM_MODEL_FUCTION_VARIABLE.svmPredict(partition_x_training)\n",
    "\n",
    "confusion_matrix_______variable, TOTAL_CALCULATE_ACCURACY, FALSE_MATRIX_SVM______________ = confusionMatrix(partition_y_training, predicted_value_of_y_data)\n",
    "\n",
    "print('Accuracy --> ', TOTAL_CALCULATE_ACCURACY)\n",
    "\n",
    "print('Confusion Matrix --> ', confusion_matrix_______variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
