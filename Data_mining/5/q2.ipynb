{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors is one of the most basic algorithm used for Classification.\n",
    "Image for post\n",
    "KNN is a non parametric algorithm (meaning, it does not make any underlying assumptions about the distribution of data)belonging to supervised learning community. KNN algorithm can also be used for regression problems.The only difference will be using averages of nearest neighbors rather than voting from nearest neighbors.\n",
    "\n",
    "# Intuition behind the algorithm :\n",
    "In K-NN algorithm output is a class membership.An object is assigned a class which is most common among its K nearest neighbors,K being the number of neighbors.Intuitively K is always a positive integer.Thus if K = 1.The object is assigned a class of its nearest neighbor.\n",
    "\n",
    "# Two questions arise if we try to understand K-NN:\n",
    "1.How do we decide the value of K?\n",
    "2.Which value is the nearest value i.e which distance metrics can be used? => Euclidean distance\n",
    "\n",
    "\n",
    "Reference-https://medium.com/@srishtisawla/k-nearest-neighbors-f77f6ee6b7f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class k_nearest_neighbour(object):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def euclidean_distance_knn(row1, row2):\n",
    "        distance_value_initial = 0.0\n",
    "        for i in range(len(row1)-1):\n",
    "            distance_value_initial += (row1[i] - row2[i])**2\n",
    "            return sqrt(distance_value_initial)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        self.labels = np.unique(Y)\n",
    "        self.features =X.shape[1]\n",
    "        self.likelihoods = self.initialize_likelihoods()\n",
    "        self.class_probabilities = self.get_nearest_neighbour(Y) \n",
    "        self.train(X, Y)\n",
    "\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def get_nearest_neighbour(outcome):\n",
    "        no_of_samples = len(outcome)\n",
    "        possibility_instance = dict(Counter(outcome))\n",
    "        for key in possibility_instance.keys():\n",
    "            possibility_instance[key] /= no_of_samples\n",
    "        return possibility_instance\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def creating_nieghbour_subset(X, Y, label):\n",
    "        row_indices = np.where(Y == label)[0]\n",
    "        return X[row_indices, :]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def get_max_value_key(dictionary):\n",
    "        return max(dictionary, key=dictionary.get)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def initialize_likelihoods(self):\n",
    "        return dict((label, defaultdict(list)) for label in self.labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        for label in self.labels:\n",
    "            subset_X = self.creating_nieghbour_subset(X, Y, label=label)\n",
    "            for feature in range(self.features):\n",
    "                self.likelihoods[label][feature] += list(subset_X[:, feature])\n",
    "\n",
    "\n",
    "        for label in self.labels:\n",
    "            for feature in range(self.features):\n",
    "                self.likelihoods[label][feature] = self.get_nearest_neighbour(self.likelihoods[label][feature])\n",
    "\n",
    "    def classification_using_k_nearest_neighbour(self, X_test):\n",
    "    \n",
    "        predicted_valuse_list = {}\n",
    "\n",
    "        \n",
    "        for label in self.labels:\n",
    "            class_probability = self.class_probabilities[label]\n",
    "            for feature in range(self.features):\n",
    "                relative_feature_values = self.likelihoods[label][feature]\n",
    "                if X_test[feature] in relative_feature_values.keys():\n",
    "                    class_probability *= relative_feature_values[X_test[feature]]\n",
    "                else:\n",
    "                    class_probability = 0\n",
    "            predicted_valuse_list[label] = class_probability\n",
    "\n",
    "\n",
    "        return self.get_max_value_key(predicted_valuse_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET LENGTH\t:\t 15\n",
      "DATASET SHAPE\t:\t (15, 5)\n",
      "\n",
      "        Age  Income Student Credit_rating Buys_computer\n",
      "0      <=30    High      No          Fair            No\n",
      "1      <=30    High      No     Excellent            No\n",
      "2   31...40    High      No          Fair           Yes\n",
      "3       >40  Medium      No          Fair           Yes\n",
      "4       >40     Low     Yes          Fair           Yes\n",
      "5       >40     Low     Yes     Excellent            No\n",
      "6   31...40     Low     Yes     Excellent           Yes\n",
      "7      <=30  Medium      No          Fair            No\n",
      "8      <=30     Low     Yes          Fair           Yes\n",
      "9       >40  Medium     Yes          Fair           Yes\n",
      "10     <=30  Medium     Yes     Excellent           Yes\n",
      "11  31...40  Medium      No     Excellent           Yes\n",
      "12  31...40    High     Yes     Excellent           Yes\n",
      "13      >40  Medium      No     Excellent            No\n",
      "14     <=30  Medium     Yes          Fair             ?\n",
      "\n",
      "Buys_computer\t:\tYes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('data/table_a.csv', sep=',')\n",
    "headers = dataset.columns\n",
    "print('DATASET LENGTH\\t:\\t', len(dataset))\n",
    "print('DATASET SHAPE\\t:\\t', dataset.shape)\n",
    "print('\\n{}'.format(dataset))\n",
    "\n",
    "dataset = dataset.to_numpy()\n",
    "X_train, y_train = np.array(dataset[:-1, :-1]), np.array(dataset[:-1, -1])\n",
    "test_data = np.array(dataset[-1, :-1])\n",
    "print('\\n{}\\t:\\t{}'.format(headers[-1], k_nearest_neighbour(X_train, y_train).classification_using_k_nearest_neighbour(test_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
